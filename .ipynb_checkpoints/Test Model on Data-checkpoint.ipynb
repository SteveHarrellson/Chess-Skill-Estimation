{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_test_Dataset = pd.read_csv('Test Data\\\\Curated_Test_Data.csv')\n",
    "\n",
    "Dataset_list = [Model_test_Dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Label_Extraction(df_in,num_of_examples = 4200):\n",
    "    df_out = df_in[0:num_of_examples]\n",
    "    df_out_feature = df_out.iloc[:,:832]\n",
    "    \n",
    "    white_elos = df_out[\"White ELO\"].astype(int)\n",
    "    black_elos = df_out[\"Black ELO\"].astype(int)\n",
    "    avg_elos = np.mean([np.array(white_elos),np.array(black_elos)],axis=0)\n",
    "    \n",
    "    df_out_label = pd.DataFrame(columns = [\"Average ELO\"])\n",
    "    df_out_label[\"Average ELO\"] = avg_elos\n",
    "    \n",
    "    #df_out_label = white_elos\n",
    "    return df_out_feature , df_out_label\n",
    "    \n",
    "def Prepare_Datasets(dataset_list):\n",
    "    out_df_feature = pd.DataFrame()\n",
    "    out_df_label = pd.DataFrame()\n",
    "    for dataframe in dataset_list:\n",
    "        feature , label = Feature_Label_Extraction(dataframe)\n",
    "        out_df_feature = out_df_feature.append(feature,ignore_index=True)\n",
    "        #out_df_label = out_df_label.append(label,ignore_index = True)\n",
    "        out_df_label = pd.concat([out_df_label,label])\n",
    "    return out_df_feature , out_df_label\n",
    "\n",
    "\n",
    "def Hot_1_encoder(df_in):\n",
    "    New_array = np.zeros([df_in.shape[0],df_in.shape[1]*13])\n",
    "    for i in range(df_in.shape[0]):\n",
    "        for j,val in enumerate(df_in.iloc[i][:]):\n",
    "            New_array[i,13*j+int(val)] = 1\n",
    "            \n",
    "    return New_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, trainy = Prepare_Datasets(Dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the agnostic model\n",
    "Test_model = keras.models.load_model('Models_middlegame_expanded_ELO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = Test_model.predict_on_batch(trainx)*1599 + 1000\n",
    "ax =plt.scatter(x_pred,trainy,s=1.5)\n",
    "plt.xlim = ([800,2600])\n",
    "plt.ylim = ([800,2600])\n",
    "x_pred = x_pred.flatten().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(Test_model.predict_on_batch(trainx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_real = list(zip(trainy.transpose()[0],x_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Brackets(real_elo):\n",
    "    bracket_dict = {\n",
    "        0 : '1000-1199',\n",
    "        1 : '1200-1399',\n",
    "        2 : '1400-1599',\n",
    "        3 : '1600-1799',\n",
    "        4 : '1800-1999', \n",
    "        5 : '2000-2199',\n",
    "        6 : '2200-2399',\n",
    "        7 : '2400-2599',\n",
    "        8 : '2600 +'\n",
    "        }\n",
    "    key = (int(real_elo)-1000)//200\n",
    "    return bracket_dict.get(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy.transpose().head()\n",
    "Build_Brackets(trainy['Average ELO'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_real_df = pd.DataFrame()\n",
    "pred_real_df[\"Real ELO\"] = trainy[\"Average ELO\"]\n",
    "pred_real_df[\"Predicted ELO\"] = x_pred\n",
    "pred_real_df[\"ELO Bracket\"] = trainy[\"Average ELO\"].astype(int).apply(lambda x:Build_Brackets(x))\n",
    "pred_real_df[\"Pred ELO Bracket\"] = [Build_Brackets(i) for i in x_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = pd.DataFrame()\n",
    "Pred_only = pd.DataFrame()\n",
    "True_only = pd.DataFrame()\n",
    "ELO_bracket = ['1000-1199','1200-1399','1400-1599','1600-1799','1800-1999','2000-2199','2200-2399']\n",
    "ELO_bracket_num = [[1000,1199],[1200,1399],[1400,1599],[1600,1799],[1800,1999],[2000,2199],[2200,2399]]\n",
    "Pred_dict = dict()\n",
    "for i in range(len(ELO_bracket)):\n",
    "    Predictions['true ELO ' + ELO_bracket[i]] = pred_real_df[\"Real ELO\"][(pred_real_df[\"Real ELO\"]>ELO_bracket_num[i][0]) & \n",
    "                                                                         (pred_real_df[\"Real ELO\"]<ELO_bracket_num[i][1])]\n",
    "    Predictions['pred ELO ' + ELO_bracket[i]] = pred_real_df[\"Predicted ELO\"][(pred_real_df[\"Real ELO\"]>ELO_bracket_num[i][0]) & \n",
    "                                                            (pred_real_df[\"Real ELO\"]<ELO_bracket_num[i][1])]\n",
    "    Pred_only['pred ELO ' + ELO_bracket[i]] =  pred_real_df[\"Predicted ELO\"][(pred_real_df[\"Real ELO\"]>ELO_bracket_num[i][0]) & \n",
    "                                                            (pred_real_df[\"Real ELO\"]<ELO_bracket_num[i][1])]\n",
    "    True_only['true ELO ' + ELO_bracket[i]] = pred_real_df[\"Real ELO\"][(pred_real_df[\"Real ELO\"]>ELO_bracket_num[i][0]) & \n",
    "                                                                         (pred_real_df[\"Real ELO\"]<ELO_bracket_num[i][1])]\n",
    "    \n",
    "    Pred_dict[ELO_bracket[i]] = pred_real_df[(pred_real_df[\"Real ELO\"]>ELO_bracket_num[i][0]) & (pred_real_df[\"Real ELO\"]<ELO_bracket_num[i][1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  pred_real_df[(pred_real_df[\"Real ELO\"]>ELO_bracket_num[0][0]) & (pred_real_df[\"Real ELO\"]<ELO_bracket_num[0][1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(Pred_dict.keys())\n",
    "ax = sns.boxplot(x = \"ELO Bracket\", y = \"Predicted ELO\" , data = pred_real_df.sort_values(by = [\"ELO Bracket\"]), whis = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "plot = sns.histplot(data = pred_real_df[\"Real ELO\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(df_in):\n",
    "    #Calculate how often the model successfully classifies a game in a given ELO bracket\n",
    "    brackets = [[i,i+199] for i in [1000,1200,1400,1600,1800,2000,2200]]\n",
    "    accuracy = []\n",
    "    colnames = list(df_in.columns)\n",
    "    for i in range(len(df_in.columns)):\n",
    "        count = 0\n",
    "        for j in df_in.loc[:,colnames[i]]:\n",
    "            if j>=brackets[i][0] and j<=brackets[i][1]:\n",
    "                count += 1    \n",
    "        accuracy.append(count/len(df_in.loc[:,colnames[i]]))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = Accuracy(Pred_only)\n",
    "acc_labels = list(Pred_only.columns)\n",
    "for i,item in enumerate(acc_labels):\n",
    "    acc_labels[i] = item.split(\"ELO\",1)[1]\n",
    "\n",
    "acc_plot = sns.barplot(x = acc_labels , y = acc)\n",
    "\n",
    "acc_plot.set_xlabel('ELO bracket')\n",
    "acc_plot.set_ylabel('Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(pred_df,true_df):\n",
    "    MSE_list = []\n",
    "    total_SE = 0\n",
    "    count = 0\n",
    "    pred_cols = list(pred_df.columns)\n",
    "    true_cols = list(true_df.columns)\n",
    "    \n",
    "    for i in range(len(pred_cols)):\n",
    "        SE = 0\n",
    "        for j in range(len(pred_df.loc[:,pred_cols[i]])):\n",
    "            SE += (pred_df.loc[j,pred_cols[i]] - true_df.loc[j,true_cols[i]])**2\n",
    "            count += 1\n",
    "        MSE_list .append(np.sqrt(SE/len(pred_df.loc[:,pred_cols[i]])))\n",
    "        total_SE += SE\n",
    "    total_MSE = total_SE/count\n",
    "    \n",
    "    return MSE_list , total_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROCgression(real_vals,pred_vals):\n",
    "    real = np.array(real_vals,dtype=int)\n",
    "    pred = np.array(pred_vals,dtype=int)\n",
    "    difference = abs(real-pred)\n",
    "    \n",
    "    \n",
    "    ROC_curve = np.zeros(max(difference)+1)\n",
    "    \n",
    "    for i in difference:\n",
    "        ROC_curve[i] += 1\n",
    "        \n",
    "    for i in range(1,len(ROC_curve)):\n",
    "        ROC_curve[i] += ROC_curve[i-1]\n",
    "        \n",
    "    ROC_curve = np.divide(ROC_curve,len(difference))\n",
    "    \n",
    "    return ROC_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = np.random.randint(pred_real_df[\"Real ELO\"].min(),\n",
    "                          high = pred_real_df[\"Real ELO\"].max(),\n",
    "                         size = np.shape(pred_real_df[\"Real ELO\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_ROC = ROCgression(pred_real_df[\"Real ELO\"],pred_real_df[\"Predicted ELO\"])\n",
    "Random_ROC = ROCgression(pred_real_df[\"Real ELO\"],random_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_dict = {'Model_ROC': Model_ROC,\n",
    "           'Random_Roc': Random_ROC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data = ROC_dict)\n",
    "ax.set_xlim([0,1599])\n",
    "ax.set_ylim([0,1.05])\n",
    "ax.set(title = 'Fraction of dataset within ELO guess tolerance')\n",
    "ax.set(xlabel = 'ELO Tolerance')\n",
    "ax.set(ylabel = 'Fraction of Dataset')\n",
    "#plt.xlim(0,1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_Classified_Dict = {}\n",
    "for label in pred_real_df[\"ELO Bracket\"].unique():\n",
    "    sliced = pred_real_df.loc[pred_real_df[\"ELO Bracket\"] == label]\n",
    "    ROC_Classified_Dict[label] = ROCgression(sliced[\"Real ELO\"],sliced[\"Predicted ELO\"])\n",
    "    \n",
    "ROC_Classified_Dict[\"Random Guess\"] = ROC_dict[\"Random_Roc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data = ROC_Classified_Dict,dashes=False)\n",
    "ax.set_xlim([0,1599])\n",
    "ax.set_ylim([0,1.05])\n",
    "ax.set(title = 'Fraction of dataset within ELO guess tolerance')\n",
    "ax.set(xlabel = 'ELO Tolerance')\n",
    "ax.set(ylabel = 'Fraction of Dataset')\n",
    "ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_Pred_Classified_Dict = {}\n",
    "for label in pred_real_df[\"Pred ELO Bracket\"].unique():\n",
    "    sliced = pred_real_df.loc[pred_real_df[\"Pred ELO Bracket\"] == label]\n",
    "    ROC_Pred_Classified_Dict[label] = ROCgression(sliced[\"Real ELO\"],sliced[\"Predicted ELO\"])\n",
    "    #print(len(sliced),label)\n",
    "    #if len(sliced) < 10:\n",
    "    #    print('popping')\n",
    "    #    ROC_Pred_Classified_Dict.pop(label)\n",
    "    \n",
    "ROC_Pred_Classified_Dict[\"Random Guess\"] = ROC_dict[\"Random_Roc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data = ROC_Pred_Classified_Dict,dashes=False)\n",
    "ax.set_xlim([0,1599])\n",
    "ax.set_ylim([0,1.05])\n",
    "ax.set(title = 'Fraction of dataset within ELO guess tolerance')\n",
    "ax.set(xlabel = 'ELO Tolerance')\n",
    "ax.set(ylabel = 'Fraction of Dataset')\n",
    "ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(pred_real_df[pred_real_df[\"Pred ELO Bracket\"] == '1200-1399'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
